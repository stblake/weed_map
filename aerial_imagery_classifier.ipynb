{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7396a43c",
   "metadata": {},
   "source": [
    "# Aerial Imagery Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97738cd5",
   "metadata": {},
   "source": [
    "Sam Blake, started 23 December 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370e1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib notebook\n",
    "%pylab notebook\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numba\n",
    "from numba import jit, prange, set_num_threads\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "from aerial_imagery_classifier import imagery_statistical_binary_classification, \\\n",
    "    show_bgr_image, show_bgra_image, show_greyscale_image \n",
    "\n",
    "plt.ioff()\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936c1ae",
   "metadata": {},
   "source": [
    "## TavistockAG Precision Weed Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0980fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_crop_1 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_1.jpg')\n",
    "dry_crop_2 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_2.jpg')\n",
    "dry_crop_3 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_3.jpg')\n",
    "dry_crop_4 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_4.jpg')\n",
    "dry_crop_5 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_5.jpg')\n",
    "dry_crop_6 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_6.jpg')\n",
    "dry_crop_7 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/crop_7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0389da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_1 = cv2.imread('../TavistockAG_Precision_Weed_Trial/spectra/weed_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6795c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '../TavistockAG_Precision_Weed_Trial/100_Orthomosaic_rgb_tile_446.tif'\n",
    "# filename = '../TavistockAG_Precision_Weed_Trial/100_Orthomosaic_rgb_tile_399.tif'\n",
    "filename = '../TavistockAG_Precision_Weed_Trial/100_Orthomosaic_rgb_tile_658.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b8d50f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba90ce5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = rasterio.open(filename)\n",
    "\n",
    "red,green,blue = dataset.read(1), dataset.read(2), dataset.read(3)\n",
    "img = np.zeros((blue.shape[0], blue.shape[1], 3), dtype = np.uint8)\n",
    "img[:,:,0] = blue\n",
    "img[:,:,1] = green\n",
    "img[:,:,2] = red\n",
    "\n",
    "density, classification_image, classification_binary = \\\n",
    "    imagery_statistical_binary_classification(\\\n",
    "        img, \\\n",
    "        [weed_1], \\\n",
    "        [dry_crop_1, dry_crop_2, dry_crop_3, dry_crop_4, dry_crop_5, dry_crop_6, dry_crop_7], \\\n",
    "        image_resize_ratio = 5, \\\n",
    "        image_blur_kernel_size = (5,5), \\\n",
    "        template_blur_kernel_size = (5,5), \\\n",
    "        template_resize_size = (64,64), \\\n",
    "        duplicate_tolerance = 5, \\\n",
    "        n_sigma_thresholds = [2.,2.25,2.5,2.75,3], \\\n",
    "        equalise = False, \\\n",
    "        denoise_classification_map = True, morph_open = 5, morph_close = 5, \\\n",
    "        export_histogram = True, \\\n",
    "        export_heatmap = True, \\\n",
    "        half_normal_dist = True, \\\n",
    "        imagery_id = filename, \\\n",
    "        plotting = True, \\\n",
    "        verbose = True)\n",
    "\n",
    "# Export classification map.\n",
    "cv2.imwrite(filename.replace('.tif',f'_CLASSIFICATION_MAP.PNG'), classification_image)\n",
    "\n",
    "# Export classification map to GeoTIFF.\n",
    "output_filename = filename.replace('.tif',f'_CLASSIFICATION_MAP.tif')\n",
    "\n",
    "kwargs = dataset.meta\n",
    "kwargs.update(\n",
    "    dtype=rasterio.uint8,\n",
    "    count=1,\n",
    "    compress='lzw')\n",
    "\n",
    "with rasterio.open(output_filename, 'w', **kwargs) as dst:\n",
    "    dst.write_band(1, 255*classification_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc393dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = '/Users/user/Documents/Research/rotavision/TavistockAG_Precision_Weed_Trial/tiles/*.tif'\n",
    "for filename in glob.glob(file_pattern):\n",
    "    print(os.path.basename(filename))\n",
    "    dataset = rasterio.open(filename)\n",
    "\n",
    "    red,green,blue = dataset.read(1), dataset.read(2), dataset.read(3)\n",
    "    img = np.zeros((blue.shape[0], blue.shape[1], 3), dtype = np.uint8)\n",
    "    img[:,:,0] = blue\n",
    "    img[:,:,1] = green\n",
    "    img[:,:,2] = red\n",
    "\n",
    "    density, classification_image, classification_binary = \\\n",
    "        imagery_statistical_binary_classification(\\\n",
    "            img, \\\n",
    "            [weed_1], \\\n",
    "            [dry_crop_1, dry_crop_2, dry_crop_3, dry_crop_4, dry_crop_5, dry_crop_6, dry_crop_7], \\\n",
    "            image_resize_ratio = 5, \\\n",
    "            image_blur_kernel_size = (5,5), \\\n",
    "            template_blur_kernel_size = (5,5), \\\n",
    "            template_resize_size = (64,64), \\\n",
    "            duplicate_tolerance = 5, \\\n",
    "            n_sigma_thresholds = [2.,2.25,2.5,2.75,3], \\\n",
    "            equalise = False, \\\n",
    "            denoise_classification_map = True, morph_open = 5, morph_close = 5, \\\n",
    "            export_histogram = False, \\\n",
    "            export_heatmap = False, \\\n",
    "            half_normal_dist = True, \\\n",
    "            imagery_id = filename, \\\n",
    "            plotting = False, \\\n",
    "            verbose = False)\n",
    "\n",
    "    # Export classification map.\n",
    "    # cv2.imwrite(filename.replace('.tif',f'_CLASSIFICATION_MAP.PNG'), classification_image)\n",
    "\n",
    "    # Export classification map to GeoTIFF.\n",
    "    output_filename = filename.replace('.tif',f'_CLASSIFICATION_MAP.tif')\n",
    "\n",
    "    kwargs = dataset.meta\n",
    "    kwargs.update(\n",
    "        dtype=rasterio.uint8,\n",
    "        count=1,\n",
    "        compress='lzw')\n",
    "\n",
    "    with rasterio.open(output_filename, 'w', **kwargs) as dst:\n",
    "        dst.write_band(1, 255*classification_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70912c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5982628",
   "metadata": {},
   "source": [
    "## nihill radish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256e03d",
   "metadata": {},
   "source": [
    "Import test imagery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b50ec655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'DJI_20221105165501_0114_V'\n",
    "# filename = 'DJI_20221105165324_0076_V'\n",
    "# filename = 'DJI_20221105171447_0579_V'\n",
    "# filename = 'DJI_20221105165900_0208_V'\n",
    "# filename = 'DJI_20221105170156_0277_V'\n",
    "# filename = 'DJI_20221105165643_0154_V'\n",
    "# filename = 'DJI_20221105171530_0596_V'\n",
    "# filename = 'DJI_20221105165306_0069_V'\n",
    "# filename = 'DJI_20221105170235_0292_V'\n",
    "# filename = 'DJI_20221105171310_0541_V'\n",
    "# filename = 'DJI_20221105170743_0413_V'\n",
    "# filename = 'DJI_20221105170442_0342_V'\n",
    "# filename = 'DJI_20221105170447_0344_V'\n",
    "# filename = 'DJI_20221105171333_0550_V'\n",
    "# filename = 'DJI_20221105171507_0587_V'\n",
    "# filename = 'DJI_20221105171510_0588_V'\n",
    "# filename = 'DJI_20221105171512_0589_V'\n",
    "# filename = 'DJI_20221105165033_0009_V'\n",
    "# filename = 'DJI_20221105165843_0201_V'\n",
    "# filename = 'DJI_20221105170513_0354_V'\n",
    "# filename = 'DJI_20221105171436_0575_V'\n",
    "filename = 'DJI_20221105171312_0542_V'\n",
    "img2 = cv2.imread(f'test/{filename}.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39083405",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_norm = np.sum(img2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "455cc697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3956, 5280)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd10a663",
   "metadata": {},
   "source": [
    "Import features for detection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b88b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57, 102, 3),\n",
       " (69, 71, 3),\n",
       " (240, 74, 3),\n",
       " (97, 92, 3),\n",
       " (183, 106, 3),\n",
       " (47, 55, 3),\n",
       " (83, 89, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nihill_radish_sample_1 = cv2.imread('nihill_radish/nihill_radish_sample_1.jpg')\n",
    "nihill_radish_sample_2 = cv2.imread('nihill_radish/nihill_radish_sample_2.jpg')\n",
    "nihill_radish_sample_3 = cv2.imread('nihill_radish/nihill_radish_sample_3.jpg')\n",
    "nihill_radish_sample_4 = cv2.imread('nihill_radish/nihill_radish_sample_4.jpg')\n",
    "nihill_radish_sample_5 = cv2.imread('nihill_radish/nihill_radish_sample_5.jpg')\n",
    "nihill_radish_sample_6 = cv2.imread('nihill_radish/nihill_radish_sample_6.jpg')\n",
    "nihill_radish_sample_7 = cv2.imread('nihill_radish/nihill_radish_sample_7.jpg')\n",
    "nihill_radish_sample_1.shape, nihill_radish_sample_2.shape, nihill_radish_sample_3.shape, \\\n",
    "nihill_radish_sample_4.shape, nihill_radish_sample_5.shape, nihill_radish_sample_6.shape, \\\n",
    "nihill_radish_sample_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d92967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((491, 182, 3), (213, 271, 3), (143, 170, 3), (620, 896, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wheat_nov_22_sample_1 = cv2.imread('nihill_wheat_nov_22/nihill_wheat_nov_22_sample_1.jpg')\n",
    "wheat_nov_22_sample_2 = cv2.imread('nihill_wheat_nov_22/nihill_wheat_nov_22_sample_2.jpg')\n",
    "wheat_nov_22_sample_3 = cv2.imread('nihill_wheat_nov_22/nihill_wheat_nov_22_sample_3.jpg')\n",
    "wheat_nov_22_dead_sample_1 = cv2.imread('nihill_wheat_nov_22/nihill_wheat_nov_22_dead_sample_1.jpg')\n",
    "wheat_nov_22_dead_sample_2 = cv2.imread('nihill_wheat_nov_22/nihill_wheat_nov_22_dead_sample_2.jpg')\n",
    "wheat_nov_22_sample_1.shape, wheat_nov_22_sample_3.shape, \\\n",
    "wheat_nov_22_dead_sample_1.shape, wheat_nov_22_dead_sample_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977325c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 561, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gravel_road_sample_1 = cv2.imread('gravel_road/gravel_road_sample_1.JPG')\n",
    "gravel_road_sample_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d638e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wheat_nov_22_dead_sample_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16a0a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "density, classification_image, spray_region = \\\n",
    "    imagery_statistical_binary_classification(\\\n",
    "        img, \\\n",
    "        [nihill_radish_sample_1, nihill_radish_sample_2, nihill_radish_sample_3, \\\n",
    "        nihill_radish_sample_4, nihill_radish_sample_5, nihill_radish_sample_6, \\\n",
    "        nihill_radish_sample_7], \\\n",
    "        [wheat_nov_22_sample_1, wheat_nov_22_sample_2, wheat_nov_22_sample_3], \\\n",
    "        image_resize_ratio = 5, \\\n",
    "        image_blur_kernel_size = (17,17), \\\n",
    "        template_blur_kernel_size = (17,17), \\\n",
    "        template_resize_size = (32,32), \\\n",
    "        duplicate_tolerance = 5, \\\n",
    "        n_sigma_thresholds = [2.,2.25,2.5,2.75,3], \\\n",
    "        export_histogram = True, \\\n",
    "        export_heatmap = True, \\\n",
    "        half_normal_dist = True, \\\n",
    "        imagery_id = filename, \\\n",
    "        plotting = True, \\\n",
    "        verbose = True)\n",
    "\n",
    "cv2.imwrite(f'test/{filename}_CLASSIFICATION_MAP_VERSION_5.PNG', classification_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be937000",
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_map = cv2.imread('test/DJI_20221105170513_0354_V_CLASSIFICATION_MAP_VERSION_4.PNG', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c35165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddb4c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "version_number = 5\n",
    "plt.ioff()\n",
    "# file_pattern = '/Users/user/Documents/Research/rotavision/model/test/*V.JPG'\n",
    "file_pattern = '/Users/user/Documents/Research/rotavision/DJI_202211051646_002_DNihill-Raddish/*.JPG'\n",
    "for filename in glob.glob(file_pattern):\n",
    "    if os.path.exists(filename.replace('.JPG',f'_CLASSIFICATION_MAP_VERSION_{version_number}.PNG')):\n",
    "        continue\n",
    "    print(os.path.basename(filename))\n",
    "    img = cv2.imread(filename)\n",
    "    density, classification_image, spray_region = \\\n",
    "        imagery_statistical_binary_classification(\\\n",
    "            img, \\\n",
    "            [nihill_radish_sample_1, nihill_radish_sample_2, nihill_radish_sample_3, \\\n",
    "            nihill_radish_sample_4, nihill_radish_sample_5, nihill_radish_sample_6, \\\n",
    "            nihill_radish_sample_7], \\\n",
    "            [wheat_nov_22_sample_1, wheat_nov_22_sample_2, wheat_nov_22_sample_3], \\\n",
    "            image_resize_ratio = 5, \\\n",
    "            image_blur_kernel_size = (17,17), \\\n",
    "            template_blur_kernel_size = (17,17), \\\n",
    "            template_resize_size = (32,32), \\\n",
    "            duplicate_tolerance = 5, \\\n",
    "            n_sigma_thresholds = [2.,2.25,2.5,2.75,3], \\\n",
    "            export_histogram = True, \\\n",
    "            export_heatmap = True, \\\n",
    "            half_normal_dist = True, \\\n",
    "            imagery_id = filename, \\\n",
    "            plotting = False, \\\n",
    "            verbose = True)\n",
    "\n",
    "    # Export classification map.\n",
    "    cv2.imwrite(filename.replace('.JPG',f'_CLASSIFICATION_MAP_VERSION_{version_number}.PNG'), classification_image)\n",
    "    \n",
    "    # Copy EXIF data from original image to classification map.\n",
    "    image_with_exif = Image.open(filename)\n",
    "    exif = image_with_exif.info['exif']\n",
    "\n",
    "    image_wo_exif = Image.open(filename.replace('.JPG',f'_CLASSIFICATION_MAP_VERSION_{version_number}.PNG'))\n",
    "    image_wo_exif.save(filename.replace('.JPG',f'_CLASSIFICATION_MAP_VERSION_{version_number}.PNG'), 'PNG', exif=exif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8ff4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_bgra_image(classification_image, axis = 'on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a9129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "500cc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy EXIF data from original image to classification map.\n",
    "from PIL import Image\n",
    "image_with_exif = Image.open('/Users/user/Documents/Research/rotavision/model/test/DJI_20221105165324_0076_V.JPG')\n",
    "exif = image_with_exif.info['exif']\n",
    "\n",
    "image_wo_exif = Image.open(\\\n",
    "'/Users/user/Documents/Research/rotavision/model/test/DJI_20221105165324_0076_V_CLASSIFICATION_MAP.PNG')\n",
    "\n",
    "image_wo_exif.save(\\\n",
    "'/Users/user/Documents/Research/rotavision/model/test/DJI_20221105165324_0076_V_CLASSIFICATION_MAP_TEST.PNG', \n",
    "'PNG', exif=exif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446bc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66000b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf5b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633d852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa814b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8003ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3062d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11290fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4872952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de077b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f520a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ec001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aeafdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b31f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
